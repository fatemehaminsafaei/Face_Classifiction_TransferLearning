{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install kaggle\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 /root/.kaggle/kaggle.json"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!kaggle datasets download -d ashishjangra27/face-mask-12k-images-dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!unzip face-mask-12k-images-dataset.zip -d data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.applications import ResNet50,MobileNet\n",
    "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import gc\n",
    "from functools import partial\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "#Transfer 'png' images to an array IMG\n",
    "def Dataset_loader(DIR, RESIZE, sigmaX=10):\n",
    "    IMG = []\n",
    "    read = lambda imname: np.asarray(Image.open(imname).convert(\"RGB\"))\n",
    "    for IMAGE_NAME in tqdm(os.listdir(DIR)):\n",
    "        PATH = os.path.join(DIR,IMAGE_NAME)\n",
    "        _, ftype = os.path.splitext(PATH)\n",
    "        if ftype == \".png\":\n",
    "            img = read(PATH)\n",
    "\n",
    "            img = cv2.resize(img, (RESIZE,RESIZE))\n",
    "\n",
    "            IMG.append(np.array(img))\n",
    "    return IMG\n",
    "\n",
    "train_data_withoutmask = np.array(Dataset_loader('/content/data/Face Mask Dataset/Train/WithoutMask',150))\n",
    "tran_data_withmask = np.array(Dataset_loader('/content/data/Face Mask Dataset/Train/WithMask',150))\n",
    "test_data_withoutmask = np.array(Dataset_loader('/content/data/Face Mask Dataset/Test/WithoutMask',150))\n",
    "test_data_withmask = np.array(Dataset_loader('/content/data/Face Mask Dataset/Test/WithMask',150))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.listdir(\"/content/data/Face Mask Dataset/Train\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Images in Train Dataset:\\n\")\n",
    "print(\"Number of Images for with Mask category:{}\".format(len(os.listdir(\"/content/data/Face Mask Dataset/Train/WithMask\"))))\n",
    "print(\"Number of Images for with WithoutMask category:{}\".format(len(os.listdir(\"/content/data/Face Mask Dataset/Train/WithoutMask\"))))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dir = \"/content/data/Face Mask Dataset/Train/\"\n",
    "test_dir = \"/content/data/Face Mask Dataset/Test\"\n",
    "validation_dir = \"/content/data/Face Mask Dataset/Validation\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#with Mask\n",
    "plt.figure(figsize=(12,7))\n",
    "for i in range(5):\n",
    "    sample = random.choice(os.listdir(train_dir+\"WithMask/\"))\n",
    "    plt.subplot(1,5,i+1)\n",
    "    img = load_img(train_dir+\"WithMask/\"+sample)\n",
    "    plt.subplots_adjust(hspace=0.001)\n",
    "    plt.xlabel(\"With Mask\")\n",
    "    plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "#without Mask\n",
    "plt.figure(figsize=(12,7))\n",
    "for i in range(5):\n",
    "    sample = random.choice(os.listdir(train_dir+\"WithoutMask/\"))\n",
    "    plt.subplot(1,5,i+1)\n",
    "    img = load_img(train_dir+\"WithoutMask/\"+sample)\n",
    "    plt.subplots_adjust(hspace=0.001)\n",
    "    plt.xlabel(\"Without Mask\")\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Image agmentation\n",
    "\n",
    "height = 150\n",
    "width=150\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255,validation_split=0.2,shear_range = 0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "\n",
    "train = train_datagen.flow_from_directory(directory=train_dir,target_size=(height,width),\n",
    "                                          class_mode=\"categorical\",batch_size=32,subset = \"training\")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "valid = train_datagen.flow_from_directory(directory=train_dir,target_size=(height,width),\n",
    "                                          class_mode=\"categorical\",batch_size=32,subset=\"validation\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications import ResNet50,MobileNet, DenseNet201, InceptionV3, NASNetLarge, InceptionResNetV2, NASNetMobile\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications import vgg16\n",
    "\n",
    "resnet = ResNet50(include_top=False,  weights='imagenet', input_shape=(150,150,3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for layer in vgg.layers:\n",
    "    layer.trainable = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten,Dense\n",
    "model = Sequential()\n",
    "model.add(resnet)\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(2, activation='softmax'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=['accuracy',sensitivity, specificity])\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"resnet_facemask.h5\",\n",
    "                             monitor=\"val_accuracy\",\n",
    "                             save_best_only=True,verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor=\"val_acc\",patience=5,verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = model.fit_generator(generator=train,steps_per_epoch=len(train)// 32,\n",
    "                              validation_data=valid,\n",
    "                             validation_steps = len(valid)//32,\n",
    "                              callbacks=[checkpoint,earlystop],\n",
    "                              epochs=20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "sensitivity = history.history['sensitivity']\n",
    "val_sensitivity = history.history['val_sensitivity']\n",
    "specificity = history.history['specificity']\n",
    "val_specificity = history.history['val_specificity']\n",
    "epochs = range(1, len(sensitivity) + 1)\n",
    "plt.plot(epochs, sensitivity, 'g', label='Training sensitivity')\n",
    "plt.plot(epochs, val_sensitivity, 'y', label='Validation sensitivity')\n",
    "plt.title('Training and validation sensitivity')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, specificity, 'g', label='Training specificity')\n",
    "plt.plot(epochs, val_specificity, 'y', label='Validation specificity')\n",
    "plt.title('Training and validation specificity')\n",
    "plt.legend()\n",
    "plt.show\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}